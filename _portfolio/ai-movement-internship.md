---
title: "AI Research Intern - Multi-view Breast Cancer Detection"
excerpt: "Implementation and refinement of 'Act Like a Radiologist' paper using Anatomy-aware Graph Networks, achieving 78.4%‚Äì92.5% Recall@[0.5,4.0]FPI compared to 68.9%‚Äì91.3% baseline"
collection: portfolio
permalink: /portfolio/ai-movement-internship/
date: 2024-08-01
venue: 'AiMovement/UM6P, Rabat, Morocco'
---

<div align="center">
<p><strong>Research Period:</strong> Summer 2024</p>
<p><strong>Institution:</strong><br>
<a href="https://aim.um6p.ma/en/home/">International Center for Artificial Intelligence of Morocco (AiMovement)</a><br>
<a href="https://www.um6p.ma/">Mohammed VI Polytechnic University (UM6P)</a>, Rabat, Morocco</p>
<p><strong>Context:</strong><br>
First foray into medical imaging ‚Ä¢ Implementation of "Act Like a Radiologist" paper</p>
</div>

---

## üìñ Introduction

Breast cancer is the most prevalent neoplastic pathology in women, accounting for an estimated 2.3 million new cases in 2022. This report details the implementation and refinement of a cutting-edge deep learning method for multi-view breast cancer detection, conducted at the International Artificial Intelligence Center of Morocco (AiMovement).

Our main focus was on the **Anatomy-aware Graph Network (AGN)**, a novel architecture that emulates a radiologist's workflow by simultaneously analyzing mediolateral oblique (MLO) and craniocaudal (CC) views. We chose this paper for its balance of resource requirements and performance, and because its code is not publicly available, presenting a unique implementation challenge.

---

## üéØ Objectives

1. **Review, implement and refine** cutting-edge methods for single-view and multi-view breast cancer detection.
2. **Develop a robust preprocessing pipeline** for data cleaning and landmark identification.
3. **Implement the AGN architecture** with resource-efficient training methods using a two-stage approach.
4. **Achieve architectural adaptation** of the AGN, focusing on augmenting or weakening features rather than the original feature removal strategy to handle small-sized datasets.
5. **Establish comparative benchmarks** against established frameworks (MaskRCNN, DETR, YOLO) on the CBIS-DDSM dataset.

---

## ‚öôÔ∏è Methodology

Our methodology is centered around the "Act Like a Radiologist" framework, which involves a multi-step process from data preprocessing to graph-based reasoning and final detection.

<div align="center">
  <img src="/images/ALR-portfolio/AGN.png" alt="AGN Architecture" width="70%">
  <p><em>AGN overall architecture with Bipartite Graph Network (BGN) and Inception Graph Network (IGN) components.</em></p>
</div>

### 1. Data Preprocessing & Structural Element Extraction

To prepare the image data for graph-based analysis, we first needed to extract key anatomical structures from the mammograms.

#### Breast Contour Detection
We employed Otsu's thresholding method to create a binary mask of the breast region. To ensure the inclusion of low-intensity pixels near the breast border, we introduced a fixed offset to the threshold. The resulting raw contour was then smoothed using B-spline interpolation.

$$t_{adjusted} = \underset{t}{\arg\max}\{\omega_0(t)\omega_1(t)[\mu_0(t) - \mu_1(t)]^2\} - \alpha$$

#### Pectoral Muscle Detection
The pectoral muscle is a critical landmark, especially in MLO views.
*   **CC Views:** As the muscle is typically not visible, we approximate its boundary as a vertical line at the medial extent of the breast.
*   **MLO Views:** We used a multi-stage approach involving ROI definition, contrast enhancement (CLAHE), combined thresholding, and edge detection to identify the pectoral muscle boundary.

#### Nipple Detection
*   **CC Views:** The nipple is identified as the lateral-most point of the breast contour.
*   **MLO Views:** We used contour curvature analysis in the lower-lateral quadrant to identify the nipple, selecting the point with the highest curvature.

### 2. Graph Construction

With the key anatomical structures identified, we constructed a graph representation of the breast for each mammogram.

#### Pseudo-Landmark Generation
We introduced "pseudo-landmarks"‚Äîanatomically consistent reference points‚Äîto enable multi-view correspondence reasoning. These landmarks were generated by:
1.  Identifying the nipple and pectoral muscle line as primary references.
2.  Defining parallel lines at equidistant intervals between them.
3.  Intersecting these lines with the breast contour.
4.  Placing landmarks at uniform intervals along each line.

<div align="center">
  <img src="/images/ALR-portfolio/pseudo.png" alt="Pseudo-landmark generation" width="60%">
  <p><em>Pseudo-landmark generation: (a) CC view with generated landmarks, (b) MLO view with generated landmarks.</em></p>
</div>

#### Graph Node Mapping
Each pseudo-landmark serves as a node in our graph. We used a k-Nearest Neighbor (kNN) mapping function to associate the continuous spatial features from the mammogram with these discrete nodes, creating a graph-based representation of the breast anatomy.

### 3. Graph-based Reasoning with AGN

The core of our method is the Anatomy-aware Graph Network (AGN), which consists of two main components:

#### Bipartite Graph Network (BGN)
The BGN models the geometric and semantic relationships between ipsilateral mammographic views (CC and MLO of the same breast). It uses a composite adjacency matrix that combines pre-computed geometric constraints with learned, instance-specific semantic similarities.

#### Inception Graph Network (IGN)
The IGN leverages the bilateral symmetry between the left and right breasts. It processes multiple neighborhood scales in parallel to handle geometric distortions between the contralateral views.

### 4. Feature Fusion and Detection

The final stage of our methodology integrates the multi-view reasoning from the BGN and IGN back into the spatial domain. The graph-based features are projected back to spatial features using a reverse kNN mapping. These enhanced features, which now encode ipsilateral and bilateral correspondence information, are then fused with the original features from the backbone network to produce the final detection results.

---

## üõ†Ô∏è Implementation Details

*   **Baseline Architecture:** Mask R-CNN with a ResNet-50 + FPN backbone.
*   **Training Strategy:** A 3-stage training process to mitigate overfitting with limited data, starting with a frozen backbone and gradually unfreezing layers.
*   **Data Augmentation:** Probabilistic online augmentation using Albumentations, including flips, rotations, and deformations.
*   **Hardware & Software:** PyTorch on an NVIDIA A100 40GB GPU, with automatic mixed precision for memory optimization.

---

## üìä Results

Our approach demonstrated a significant improvement over the baseline, validating the effectiveness of the AGN framework.

### FROC Performance Comparison

| Model | R@0.5FPI | R@1.0FPI | R@2.0FPI | R@3.0FPI | R@4.0FPI |
|---|---|---|---|---|---|
| **ALR MaskRCNN+FPN** | 76.0% | 82.5% | 88.7% | 90.8% | 91.4% |
| **Our MaskRCNN+FPN** | 68.9% | 79.8% | 86.3% | 90.2% | 91.3% |
| **Our AGRCNN** | **78.4%** | **85.5%** | **90.1%** | **91.6%** | **92.5%** |

<div align="center">
  <img src="/images/ALR-portfolio/agn_froc.png" alt="FROC Comparison" width="70%">
  <p><em>Comparative FROC analysis of our implemented models against the original paper's results.</em></p>
</div>

### Key Performance Improvements

*   **+9.5% improvement** in Recall@0.5FPI compared to our baseline Mask R-CNN.
*   **Superior performance** despite using the smaller CBIS-DDSM dataset compared to the original paper's DDSM.
*   **Consistent improvement** across all False Positive Per Image (FPI) thresholds.

---

## üí¨ Discussion & Conclusion

### Major Technical Contributions

A key challenge we identified was that the original AGN attention mechanism was "destructive," as it could permanently eliminate features learned by the Mask R-CNN backbone. Our main contribution was to implement a **ResNet-inspired residual solution**:

```python
# Residual attention mechanism with feature preservation
ign_spatial_features = examined_features * (2.0 * ign_attention_map)
ign_spatial_features = ign_spatial_features + 0.2 * examined_features
```
This simple but effective change transforms the effective attention range from [0, 1] to [0.2, 2.2], allowing the network to both suppress and enhance features, rather than only suppressing them. This feature preservation was crucial for achieving high performance.

### Challenges and Future Directions

The primary limitation of this work was the small size of the multi-view dataset (111 tri-view groups from CBIS-DDSM). While our progressive training strategy and residual connections helped, a larger dataset would be beneficial.

Future work could focus on:
*   Adding a classification module to differentiate between benign and malignant lesions.
*   Optimizing the model for faster inference.
*   Exploring 3D analysis techniques, such as Digital Breast Tomosynthesis (DBT), to resolve tissue superposition ambiguities.

---

## üîó References

[1] Liu, Y., et al. (2020). "Act Like a Radiologist: Towards Reliable Multi-view Correspondence Reasoning for Mammogram Mass Detection". In MICCAI 2020.
[2] He, K., et al. (2017). "Mask R-CNN". In Proceedings of the IEEE international conference on computer vision.